{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The GPT Language Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "\n",
    "Here are the packages we need to import."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from nlpmodels.models import gpt\n",
    "from nlpmodels.utils import train,utils,gpt_sampler\n",
    "from nlpmodels.utils.elt import gpt_dataset\n",
    "from argparse import Namespace\n",
    "utils.set_seed_everywhere()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Language Model: WikiText2\n",
    "\n",
    "We will try to train our transformer model to learn how to predict the next word in torchtext WikiText2 database.\n",
    "I took the first 300k from the training set to reduce computation time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper-parameters\n",
    "\n",
    "These are the data processing and model training hyper-parameters for this run. Note that we are running a smaller model\n",
    "than cited in the paper for fewer iterations...on a CPU. This is meant merely to demonstrate it works."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "        # Model hyper-parameters\n",
    "        num_layers_per_stack=2,  # original value = 12\n",
    "        dim_model=12, #original value = 768\n",
    "        dim_ffn=48, # original value = 3072\n",
    "        num_heads=2, # original value = 12\n",
    "        block_size=64, # original value = 512, context window\n",
    "        dropout=0.1,\n",
    "        # Training hyper-parameters\n",
    "        num_epochs=1, #obviously super short\n",
    "        learning_rate=0.0,\n",
    "        batch_size=32, #original value = 64\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1lines [00:00,  3.74lines/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, vocab = gpt_dataset.GPTDataset.get_training_dataloader(args)\n",
    "model = gpt.GPT(vocab_size = len(vocab),\n",
    "            num_layers_per_stack= args.num_layers_per_stack,\n",
    "            dim_model = args.dim_model,\n",
    "            dim_ffn = args.dim_ffn,\n",
    "            num_heads = args.num_heads,\n",
    "            block_size = args.block_size,\n",
    "            dropout = args.dropout)\n",
    "trainer = train.GPTTrainer(args,vocab.mask_index,model,train_loader,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Self-supervised training\n",
    "Now we will run the first step in GPT training process, where we train the model to\n",
    "maximize the objective\n",
    "\n",
    "```\n",
    "max p(x[k]|x[k-1],[k-2],...x[k-block_size])\n",
    "```.\n",
    "\n",
    "This is an unsupervised (more aptly described as \"self-supervised\") loss. After this model is trained,\n",
    "we can run then continue it onto another problem (can freeze layers to only continue training the top layers)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0]: 100%|██████████| 9375/9375 [2:30:30<00:00,  1.04it/s, loss=5.17]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that this model was run for a **very** short period of time. The goal is just to show how this works - you can\n",
    "play with the hyper-parameters as you see fit.\n",
    "We only ran for 1 epoch, on a much smaller model,\n",
    "with a smaller dataset than was suggested in the paper.\n",
    "\n",
    "Let's see if the output the model completes makes any sense."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Completes A Sequence\n",
    "\n",
    "In the spirit of Kaparthy's minGPT::play_char notebook, we can use a greedy_sampler to see how the model\n",
    "continues a sequence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"ernest hemingway first novel , the sun also rises , \" \\\n",
    "         \"treats of certain of those younger americas concerning whom gertrude stein has remarked :\" \\\n",
    "         \" you are all a lost generation . this is the novel for which a keen appetite was stimulated by\" \\\n",
    "         \" mr . hemingway 's exciting volume of short stories. \" \\\n",
    "         \" the clear objectivity and the sustained intensity of the stories , \" \\\n",
    "         \"and their concentration upon action in the present moment, seemed to point to a failure to project \" \\\n",
    "         \"a novel in terms of the same method, yet a resort to any other method would have let down the \" \\\n",
    "         \"reader's expectations. it is a relief to find that the sun also rises maintains the same heightened , \" \\\n",
    "         \"intimate tangibility as the shorter narratives and does it in the same kind of weighted, quickening prose. \"\n",
    "prompt_tensor = torch.LongTensor([[vocab.lookup_token(s) for s in prompt.split(\" \")]])\n",
    "prompt_tensor_batch = trainer._reformat_data((prompt_tensor,None))\n",
    "steps = 64\n",
    "y_hat_indices = gpt_sampler.sampler(model=model, data=prompt_tensor_batch,\n",
    "                                          steps=steps,block_size=64,do_sample=True).src\n",
    "y_hat_tokens = ' '.join([vocab.lookup_index(int(idx)) for idx in y_hat_indices[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the prompt it was provided, a review of Ernest Hemingway's novel, The Sun Also Rises:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ernest hemingway first novel , the sun also\n",
      "rises , treats of certain of those younger\n",
      "americas concerning whom gertrude stein has remarked :\n",
      "you are all a lost generation . this\n",
      "is the novel for which a keen appetite\n",
      "was stimulated by mr . hemingway 's exciting\n",
      "volume of short stories.  the clear objectivity\n",
      "and the sustained intensity of the stories ,\n",
      "and their concentration upon action in the present\n",
      "moment, seemed to point to a failure to\n",
      "project a novel in terms of the same\n",
      "method, yet a resort to any other method\n",
      "would have let down the reader's expectations. it\n",
      "is a relief to find that the sun\n",
      "also rises maintains the same heightened , intimate\n",
      "tangibility as the shorter narratives and does it\n",
      "in the same kind of weighted, quickening prose.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,len(prompt.split(\" \")),8):\n",
    "    print(\" \".join(prompt.split(\" \")[idx:idx+8]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Working off that sequence, here is how the model completed the next 64 words in this review:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> were started to <unk> olajuwon has been\n",
      "bed at in polish jazz @-@ overall films\n",
      ". around his violent several name or from\n",
      "the community in some vessels , passengers is\n",
      "being to direct works gas nuclear works of\n",
      "relationships and he believes that who chose taken\n",
      "the nba party , germany with distinguished war\n",
      "and on a representation . kevin bull ,\n",
      "but\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,len(y_hat_tokens.split(\" \")),8):\n",
    "    print(\" \".join(y_hat_tokens.split(\" \")[idx:idx+8]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Well, as expected... this doesn't make any sense really. Pockets of words make sense, but overall it does not.\n",
    "As the language model is trained further and using more parameters, we would expect the believability of this text to increase."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised training\n",
    "\n",
    "Once the model is trained in the self-supervised phase, go forth and apply it to a different problem!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}