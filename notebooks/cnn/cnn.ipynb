{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN-based Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Colab Setup\n",
    "\n",
    "You can skip this section if not running on Google's colab."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If running with GPUs, sanity check that the GPUs are enabled."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Should be True. If not, debug (Note: version of pytorch I used is not capatible with CUDA drivers on colab. Follow these instructions here explicitly)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This should be \"/content\" on Colab."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, if running from colab, you must install the package. (You may skip if you installed already)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone --single-branch --branch colab https://github.com/will-thompson-k/deeplearning-nlp-models.git\n",
    "%cd deeplearning-nlp-models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install datasets torchtext==0.7.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python setup.py install"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "\n",
    "Here are the packages we need to import."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from nlpmodels.models import text_cnn\n",
    "from nlpmodels.utils import train,utils\n",
    "from nlpmodels.utils.elt import text_cnn_dataset\n",
    "from argparse import Namespace\n",
    "utils.set_seed_everywhere()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis with CNNs\n",
    "\n",
    "Following the logic in Kim's paper, we are running an embedding + convolutional layer architecture in order\n",
    "to conduct sentiment analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper-parameters\n",
    "\n",
    "These are the data processing and model training hyper-parameters for this run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "        # Model hyper-parameters\n",
    "        max_sequence_length=50, #Often you chose it such that there is minimal padding. 95th percentile=582\n",
    "        dim_model=128, # Embedding size controls the projection of a vocabulary.\n",
    "        num_filters=128, # output filters from convolution\n",
    "        window_sizes=[3,5,7], # different filter sizes, total number of filters len(window_sizes)*num_filters\n",
    "        num_classes=2, # binary classification problem\n",
    "        dropout=0.5, # 0.5 from original implementation, kind of high compared to other papers (usually 0.1)\n",
    "        # Training hyper-parameters\n",
    "        num_epochs=30,\n",
    "        learning_rate=1.e-6, #chosing LR is important, often accompanied with scheduler to change\n",
    "        batch_size=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000lines [00:02, 11122.99lines/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, vocab = text_cnn_dataset.TextCNNDataset.get_training_dataloader(args)\n",
    "model = text_cnn.TextCNN(vocab_size = len(vocab),\n",
    "                        dim_model = args.dim_model,\n",
    "                        num_filters = args.num_filters,\n",
    "                        window_sizes =  args.window_sizes,\n",
    "                        num_classes = args.num_classes,\n",
    "                        dropout = args.dropout)\n",
    "\n",
    "trainer = train.TextCNNTrainer(args, vocab.mask_index, model, train_loader, vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's run this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0]: 100%|██████████| 391/391 [01:26<00:00,  4.53it/s, accuracy=50, loss=15.2]  \n",
      "[Epoch 1]: 100%|██████████| 391/391 [01:24<00:00,  4.64it/s, accuracy=50, loss=14.4]  \n",
      "[Epoch 2]: 100%|██████████| 391/391 [01:19<00:00,  4.90it/s, accuracy=50, loss=13.6]  \n",
      "[Epoch 3]: 100%|██████████| 391/391 [01:20<00:00,  4.85it/s, accuracy=50.1, loss=15.7]\n",
      "[Epoch 4]: 100%|██████████| 391/391 [01:21<00:00,  4.78it/s, accuracy=50.3, loss=14.1]\n",
      "[Epoch 5]: 100%|██████████| 391/391 [01:44<00:00,  3.75it/s, accuracy=50.2, loss=12.6]\n",
      "[Epoch 6]:  27%|██▋       | 105/391 [00:30<01:38,  2.91it/s, accuracy=13.6, loss=23.1]"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Review\n",
    "\n",
    "The goal is just to show how this works - you can play with the hyper-parameters as you see fit.\n",
    "In an ideal situation, we would check the data against an unseen val or test set to diagnose performance.\n",
    "\n",
    "#### Parameter importance\n",
    "\n",
    "In playing with the model, there are a few things to note:\n",
    "\n",
    "- *l2 regularization*: Unlike the original paper, I didn't end up using L2 regularization.\n",
    "- *dictionary pruning*: The original dictionary had 75k tokens. I ended up pruning any <.1% frequency, bringing it down\n",
    "to <20k.\n",
    "- *max_sequence_length*: Generally, you don't want to truncate the sentences and want to set this to the longest sequence.\n",
    "However, here the max == ~2k while the 95th percentile was ~500, so I chose to truncate some sentences.\n",
    "- *learning_rate*: I set the parameter to be static,\n",
    "but often times it makes sense to use a scheduler to allow larger parameter changes initially and then fine-tune over updates.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}