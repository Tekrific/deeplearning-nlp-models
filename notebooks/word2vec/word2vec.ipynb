{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TuFB1te9QZi4"
      },
      "source": [
        "# Skip-gram in Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8xfHObtRQZi5"
      },
      "source": [
        "## Colab Setup\n",
        "\n",
        "You can skip this section if not running on Google's colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KATZhWEKdvCt"
      },
      "source": [
        "If running with GPUs, sanity check that the GPUs are enabled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbMGzCvnhLoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74e74ce-6cfa-45e2-e000-23caa18e2fee"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec  2 03:20:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ4c_IP5dt6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c668b871-6079-4eca-c354-4d23c0996167"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blhzRQd4icDp"
      },
      "source": [
        "The above should be True. If not, debug (Note: version of pytorch I used is not capatible with CUDA drivers on colab. Follow these instructions here explicitly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TomQVpu6d1Qe",
        "outputId": "a4c6146f-a3ab-430a-b5b9-c7261bfb6c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsWgkCzbd4x8"
      },
      "source": [
        "This should be \"/content\" on Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DYyFNKVQsuU"
      },
      "source": [
        "First, if running from colab, you must install the package. (You may skip if you installed already)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7_3_DdKQwsI"
      },
      "source": [
        "!git clone --single-branch --branch colab https://github.com/will-thompson-k/deeplearning-nlp-models.git\n",
        "%cd deeplearning-nlp-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgWIaSV7SJ-y"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ3IPlXrQ93X"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXZn0d9wiw4S"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPl37AC7Q7Ge"
      },
      "source": [
        "Here are the packages we need to import."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "R1xTK4WDQZi5"
      },
      "source": [
        "from nlpmodels.models import word2vec\n",
        "from nlpmodels.utils import utils, train\n",
        "from nlpmodels.utils.elt import skipgram_dataset\n",
        "from argparse import Namespace\n",
        "import torch\n",
        "utils.set_seed_everywhere()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_FAdhDejQZi6"
      },
      "source": [
        "## Hyper-parameters\n",
        "\n",
        "These are the data processing, skip-gram, and model training hyper-parameters for this run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Parameters\n"
        },
        "id": "IjnfEI2EQZi6"
      },
      "source": [
        "args = Namespace(\n",
        "    # skip gram data hyper-parameters\n",
        "    context_window_size = 5,\n",
        "    subsample_t = 10.e-5, # param for sub-sampling frequent words (10.e-5 suggested by paper)\n",
        "    # Model hyper-parameters\n",
        "    embedding_size = 512,\n",
        "    negative_sample_size= 20, # k examples to be used in negative sampling loss function\n",
        "    # Training hyper-parameters\n",
        "    num_epochs=5,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size = 4096,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "p_RwySKWQZi6"
      },
      "source": [
        "## Get Data\n",
        "\n",
        "Call the function that grabs training data (via hugging faces) and a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Get data\n"
        },
        "id": "F6YRdoMSQZi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3922363e-c093-4688-82d4-fbce95173666"
      },
      "source": [
        "train_dataloader, vocab = skipgram_dataset.SkipGramDataset.get_training_dataloader(args.context_window_size,\n",
        "                                                                                   args.subsample_t,\n",
        "                                                                                   args.batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Variables\n"
        },
        "id": "NefAdy_3QZi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a62cdb-431e-4149-a099-f9f51a39fa50"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "print(f\"The gist: context_window_size = {args.context_window_size}, \"\n",
        "      f\"batch_size = {args.batch_size}, vocab_size = {vocab_size}, \"\n",
        "      f\"embedding_size = {args.embedding_size}, k = {args.negative_sample_size}, \"\n",
        "      f\"train_size = {len(train_dataloader.dataset)}\"\n",
        "      )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The gist: context_window_size = 5, batch_size = 4096, vocab_size = 61811, embedding_size = 512, k = 20, train_size = 16103772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "fCIfZnhkQZi7"
      },
      "source": [
        "## Training\n",
        "\n",
        "Here we build the model and call the trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Setting up training the model\n"
        },
        "id": "Dr8YY7JiQZi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cee3324-d1da-4137-f391-399c32526f29"
      },
      "source": [
        "word_frequencies = torch.from_numpy(vocab.get_word_frequencies())\n",
        "model = word2vec.SkipGramNSModel(vocab_size, args.embedding_size, args.negative_sample_size,word_frequencies)\n",
        "trainer = train.Word2VecTrainer(args,model,train_dataloader)\n",
        "trainer.run()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0]: 100%|██████████| 3932/3932 [04:01<00:00, 16.25it/s, loss=0.885]\n",
            "[Epoch 1]: 100%|██████████| 3932/3932 [04:05<00:00, 16.01it/s, loss=0.751]\n",
            "[Epoch 2]: 100%|██████████| 3932/3932 [04:08<00:00, 15.83it/s, loss=0.717]\n",
            "[Epoch 3]: 100%|██████████| 3932/3932 [04:07<00:00, 15.91it/s, loss=0.704]\n",
            "[Epoch 4]: 100%|██████████| 3932/3932 [04:05<00:00, 16.00it/s, loss=0.703]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zw_Ee0hbQZi7"
      },
      "source": [
        "## Examine Similarity of Embeddings\n",
        "\n",
        "Now that we've trained our embeddings, let's see if the words that are clustered together make any sense.\n",
        "\n",
        "We will use cosine similarity to find the embeddings that are most similar in the embeddings space. This is one metric\n",
        "for similarity. Another popular metric is based on euclidean distance. To use that metric, check out pytorch's\n",
        "cdist() function. Also, can't speak highly enough of `spotify::annoy` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Get the embeddings\n"
        },
        "id": "x-_W3wOrQZi7"
      },
      "source": [
        "embeddings = model.get_embeddings().to(torch.device('cpu'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcwxFtWmjV64",
        "outputId": "3b24ebad-71c7-4531-bb51-c22c334da3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embeddings"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.1830e-04, -6.3485e-04,  6.9642e-04,  ..., -3.4787e-04,\n",
              "         -8.6980e-04,  2.1303e-04],\n",
              "        [-9.1912e-04, -7.5858e-04, -9.1346e-04,  ..., -6.2681e-04,\n",
              "          4.7648e-04,  5.9994e-04],\n",
              "        [-9.0853e-04,  6.7023e-04, -2.8429e-05,  ...,  4.2949e-04,\n",
              "          6.4231e-04, -2.3924e-04],\n",
              "        ...,\n",
              "        [ 1.4746e-02, -1.4129e-02,  1.6054e-02,  ...,  1.4172e-02,\n",
              "         -1.5293e-02,  1.5223e-02],\n",
              "        [ 4.1555e-02, -4.0126e-02,  4.1399e-02,  ...,  4.1131e-02,\n",
              "         -4.0341e-02,  4.0407e-02],\n",
              "        [ 3.4955e-02, -3.6053e-02,  3.5510e-02,  ...,  3.4885e-02,\n",
              "         -3.5795e-02,  3.4757e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UY7Edm_vQZi7"
      },
      "source": [
        "### Computer\n",
        "\n",
        "Let's see the top 10 words associated with \"computer\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% computer similar words\n"
        },
        "id": "BSOnHyWBQZi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c41b219-8da5-4a98-9fc1-94c05404936c"
      },
      "source": [
        "utils.get_cosine_similar(\"computer\",vocab._token_to_idx,embeddings)[0:10]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('financial', tensor(0.9999)),\n",
              " ('force', tensor(0.9999)),\n",
              " ('low', tensor(0.9999)),\n",
              " ('india', tensor(0.9999)),\n",
              " ('stock', tensor(0.9999)),\n",
              " ('called', tensor(0.9999)),\n",
              " ('action', tensor(0.9999)),\n",
              " ('saying', tensor(0.9999)),\n",
              " ('official', tensor(0.9999)),\n",
              " ('so', tensor(0.9999))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1dBWUJm5QZi7"
      },
      "source": [
        "### Market\n",
        "\n",
        "Let's see the top 5 words associated with \"market\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% market similar words\n"
        },
        "id": "JoKo6JySQZi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310bad47-45a5-497a-ffd2-bdb44196655e"
      },
      "source": [
        "utils.get_cosine_similar(\"market\",vocab._token_to_idx,embeddings)[0:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('but', tensor(0.9999)),\n",
              " ('with', tensor(0.9999)),\n",
              " ('as', tensor(0.9999)),\n",
              " ('for', tensor(0.9999)),\n",
              " ('after', tensor(0.9999)),\n",
              " ('final', tensor(0.9999)),\n",
              " ('an', tensor(0.9999)),\n",
              " ('against', tensor(0.9999)),\n",
              " ('over', tensor(0.9999)),\n",
              " ('us', tensor(0.9999))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}