{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "word2vec.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "TuFB1te9QZi4"
   },
   "source": [
    "# Skip-gram in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "8xfHObtRQZi5"
   },
   "source": [
    "## Colab Setup\n",
    "\n",
    "You can skip this section if not running on Google's colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KATZhWEKdvCt"
   },
   "source": [
    "If running with GPUs, sanity check that the GPUs are enabled."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RbMGzCvnhLoB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "272630fa-9637-4b74-b46f-ce1cb03ad860"
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Tue Dec  1 12:32:24 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XQ4c_IP5dt6K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c542cfef-2fdd-4712-ae02-4c326a64826a"
   },
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blhzRQd4icDp"
   },
   "source": [
    "The above should be True. If not, debug (Note: version of pytorch I used is not capatible with CUDA drivers on colab. Follow these instructions here explicitly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DYyFNKVQsuU"
   },
   "source": [
    "First, if running from colab, you must install the package. (You may skip if you installed already)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7_3_DdKQwsI",
    "outputId": "8e886e6e-1372-46c8-e8eb-d79fc6bdbaf9"
   },
   "source": [
    "!git clone --single-branch --branch colab https://github.com/will-thompson-k/deeplearning-nlp-models.git\n",
    "%cd deeplearning-nlp-models"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'deeplearning-nlp-models'...\n",
      "remote: Enumerating objects: 78, done.\u001B[K\n",
      "remote: Counting objects: 100% (78/78), done.\u001B[K\n",
      "remote: Compressing objects: 100% (63/63), done.\u001B[K\n",
      "remote: Total 904 (delta 41), reused 30 (delta 15), pack-reused 826\u001B[K\n",
      "Receiving objects: 100% (904/904), 3.63 MiB | 3.13 MiB/s, done.\n",
      "Resolving deltas: 100% (533/533), done.\n",
      "/content/deeplearning-nlp-models\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgWIaSV7SJ-y",
    "outputId": "49767bd8-4f75-4b7a-ce98-6ee214b2c269"
   },
   "source": [
    "!pip install datasets"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
      "\r\u001B[K     |██▏                             | 10kB 18.6MB/s eta 0:00:01\r\u001B[K     |████▎                           | 20kB 21.9MB/s eta 0:00:01\r\u001B[K     |██████▍                         | 30kB 11.2MB/s eta 0:00:01\r\u001B[K     |████████▌                       | 40kB 9.1MB/s eta 0:00:01\r\u001B[K     |██████████▋                     | 51kB 4.4MB/s eta 0:00:01\r\u001B[K     |████████████▉                   | 61kB 5.0MB/s eta 0:00:01\r\u001B[K     |███████████████                 | 71kB 5.2MB/s eta 0:00:01\r\u001B[K     |█████████████████               | 81kB 5.5MB/s eta 0:00:01\r\u001B[K     |███████████████████▏            | 92kB 5.8MB/s eta 0:00:01\r\u001B[K     |█████████████████████▎          | 102kB 6.1MB/s eta 0:00:01\r\u001B[K     |███████████████████████▌        | 112kB 6.1MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▋      | 122kB 6.1MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▊    | 133kB 6.1MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▉  | 143kB 6.1MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 153kB 6.1MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 163kB 6.1MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
      "Collecting pyarrow>=0.17.1\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
      "\u001B[K     |████████████████████████████████| 17.7MB 211kB/s \n",
      "\u001B[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
      "Collecting xxhash\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
      "\u001B[K     |████████████████████████████████| 245kB 48.3MB/s \n",
      "\u001B[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: pyarrow, xxhash, datasets\n",
      "  Found existing installation: pyarrow 0.14.1\n",
      "    Uninstalling pyarrow-0.14.1:\n",
      "      Successfully uninstalled pyarrow-0.14.1\n",
      "Successfully installed datasets-1.1.3 pyarrow-2.0.0 xxhash-2.0.0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ3IPlXrQ93X",
    "outputId": "1bdb79db-10e5-4c14-c3bf-dece6839b921"
   },
   "source": [
    "!python setup.py install"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXZn0d9wiw4S"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPl37AC7Q7Ge"
   },
   "source": [
    "Here are the packages we need to import."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "R1xTK4WDQZi5"
   },
   "source": [
    "from nlpmodels.models import word2vec\n",
    "from nlpmodels.utils import utils, train\n",
    "from nlpmodels.utils.elt import skipgram_dataset\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "utils.set_seed_everywhere()"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_FAdhDejQZi6"
   },
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "These are the data processing, skip-gram, and model training hyper-parameters for this run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Parameters\n"
    },
    "id": "IjnfEI2EQZi6"
   },
   "source": [
    "args = Namespace(\n",
    "    # skip gram data hyper-parameters\n",
    "    context_window_size = 5,\n",
    "    subsample_t = 10.e-5, # param for sub-sampling frequent words (10.e-5 suggested by paper)\n",
    "    # Model hyper-parameters\n",
    "    embedding_size = 300,\n",
    "    negative_sample_size= 20, # k examples to be used in negative sampling loss function\n",
    "    # Training hyper-parameters\n",
    "    num_epochs=50,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size = 4096,\n",
    ")"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "p_RwySKWQZi6"
   },
   "source": [
    "## Get Data\n",
    "\n",
    "Call the function that grabs training data (via hugging faces) and a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Get data\n"
    },
    "id": "F6YRdoMSQZi6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "073580ee-ec05-4648-d31c-273a97b46c3f"
   },
   "source": [
    "train_dataloader, vocab = skipgram_dataset.SkipGramDataset.get_training_dataloader(args.context_window_size,\n",
    "                                                                                   args.subsample_t,\n",
    "                                                                                   args.batch_size)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Variables\n"
    },
    "id": "NefAdy_3QZi7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3f2f004a-af5e-42d3-cc09-8f152204c66c"
   },
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"The gist: context_window_size = {args.context_window_size}, \"\n",
    "      f\"batch_size = {args.batch_size}, vocab_size = {vocab_size}, \"\n",
    "      f\"embedding_size = {args.embedding_size}, k = {args.negative_sample_size}, \"\n",
    "      f\"train_size = {len(train_dataloader.dataset)}\"\n",
    "      )"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "The gist: context_window_size = 5, batch_size = 4096, vocab_size = 61811, embedding_size = 300, k = 20, train_size = 16100272\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "fCIfZnhkQZi7"
   },
   "source": [
    "## Training\n",
    "\n",
    "Here we build the model and call the trainer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Setting up training the model\n"
    },
    "id": "Dr8YY7JiQZi7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "outputId": "bc3f5879-090e-48f0-bc02-ea787283fe36"
   },
   "source": [
    "word_frequencies = torch.from_numpy(vocab.get_word_frequencies())\n",
    "model = word2vec.SkipGramNSModel(vocab_size, args.embedding_size, args.negative_sample_size,word_frequencies)\n",
    "trainer = train.Word2VecTrainer(args,model,train_dataloader)\n",
    "trainer.run()"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[Epoch 0]: 100%|██████████| 3931/3931 [02:17<00:00, 28.58it/s, loss=1]\n",
      "[Epoch 1]: 100%|██████████| 3931/3931 [02:16<00:00, 28.82it/s, loss=0.759]\n",
      "[Epoch 2]: 100%|██████████| 3931/3931 [02:20<00:00, 28.05it/s, loss=0.729]\n",
      "[Epoch 3]:  34%|███▎      | 1319/3931 [00:47<01:21, 32.03it/s, loss=0.717]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": []
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "zw_Ee0hbQZi7"
   },
   "source": [
    "## Examine Similarity of Embeddings\n",
    "\n",
    "Now that we've trained our embeddings, let's see if the words that are clustered together make any sense.\n",
    "\n",
    "We will use cosine similarity to find the embeddings that are most similar in the embeddings space. This is one metric\n",
    "for similarity. Another popular metric is based on euclidean distance. To use that metric, check out pytorch's\n",
    "cdist() function. Also, can't speak highly enough of `spotify::annoy` package."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% Get the embeddings\n"
    },
    "id": "x-_W3wOrQZi7"
   },
   "source": [
    "embeddings = model.get_embeddings().to(torch.device('cpu'))"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "UY7Edm_vQZi7"
   },
   "source": [
    "### Computer\n",
    "\n",
    "Let's see the top 10 words associated with \"computer\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% computer similar words\n"
    },
    "id": "BSOnHyWBQZi7",
    "outputId": "dbb7e482-800a-4297-ab90-28ae66ac4b52",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "utils.get_cosine_similar(\"computer\",vocab._token_to_idx,embeddings)[0:10]"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the', tensor(0.9999)),\n",
       " ('ron', tensor(0.9999)),\n",
       " ('raptors', tensor(0.9999)),\n",
       " ('backed', tensor(0.9999)),\n",
       " ('rated', tensor(0.9999)),\n",
       " ('ramadi', tensor(0.9999)),\n",
       " ('returning', tensor(0.9999)),\n",
       " ('veterans', tensor(0.9999)),\n",
       " ('arrest', tensor(0.9999)),\n",
       " ('unbeaten', tensor(0.9999))]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "1dBWUJm5QZi7"
   },
   "source": [
    "### Market\n",
    "\n",
    "Let's see the top 5 words associated with \"market\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% market similar words\n"
    },
    "id": "JoKo6JySQZi7",
    "outputId": "59118a2a-22a5-45b5-c0b8-dcac8ab830c0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "utils.get_cosine_similar(\"market\",vocab._token_to_idx,embeddings)[0:10]"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('maria', tensor(0.9999)),\n",
       " ('the', tensor(0.9999)),\n",
       " ('malicious', tensor(0.9999)),\n",
       " ('quarter', tensor(0.9999)),\n",
       " ('lay', tensor(0.9999)),\n",
       " ('hire', tensor(0.9999)),\n",
       " ('rush', tensor(0.9999)),\n",
       " ('did', tensor(0.9999)),\n",
       " ('passing', tensor(0.9999)),\n",
       " ('capriati', tensor(0.9999))]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 26
    }
   ]
  }
 ]
}