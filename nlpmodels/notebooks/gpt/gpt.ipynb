{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The GPT Language Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "\n",
    "Here are the packages we need to import."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nlpmodels.models import gpt\n",
    "from nlpmodels.utils import train,utils,gpt_dataset,gpt_sampler\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "utils.set_seed_everywhere()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Language Model: WikiText2\n",
    "\n",
    "We will try to train our transformer model to learn how to predict the next word in torchtext WikiText2 database.\n",
    "I took the first 300k from the training set to reduce computation time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper-parameters\n",
    "\n",
    "These are the data processing and model training hyper-parameters for this run. Note that we are running a smaller model\n",
    "than cited in the paper for fewer iterations...on a CPU. This is meant merely to demonstrate it works."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "        # Model hyper-parameters\n",
    "        num_layers_per_stack=2,  # original value = 12\n",
    "        dim_model=12, #original value = 768\n",
    "        dim_ffn=48, # original value = 3072\n",
    "        num_heads=2, # original value = 12\n",
    "        block_size=64, # original value = 512, context window\n",
    "        dropout=0.1,\n",
    "        # Training hyper-parameters\n",
    "        num_epochs=15,\n",
    "        learning_rate=0.0,\n",
    "        batch_size=128, #original value = 64\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader, vocab = gpt_dataset.GPTDataset.get_training_dataloader(args)\n",
    "model = gpt.GPT(vocab_size = len(vocab),\n",
    "            num_layers_per_stack= args.num_layers_per_stack,\n",
    "            dim_model = args.dim_model,\n",
    "            dim_ffn = args.dim_ffn,\n",
    "            num_heads = args.num_heads,\n",
    "            block_size = args.block_size,\n",
    "            dropout = args.dropout)\n",
    "trainer = train.GPTTrainer(args,vocab.mask_index,model,train_loader,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Completes A Sequence\n",
    "\n",
    "In the spirit of Kaparthy's minGPT::play_char notebook, we can use a greedy_sampler to see how the model\n",
    "continues a sequence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"The government found\"\n",
    "prompt_tensor = torch.LongTensor([vocab.lookup_token(s) for s in prompt])\n",
    "steps = 500\n",
    "yhat_indices = gpt_sampler.greedy_sampler(model, prompt_tensor, steps, sample=True)[0]\n",
    "yhat_tokens = ''.join([vocab.lookup_index(idx) for idx in yhat_indices])\n",
    "print(yhat_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}